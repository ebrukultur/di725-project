# Visionâ€“Language Model Improvements for Remote Sensing Image Captioning  
**PhaseÂ 1 Report** â€“ DI725: Transformers and Attention-Based Deep Networks

**Author:** Ebru KÃ¼ltÃ¼r BaÅŸaran  
**Affiliation:** Middle East Technical University, Informatics Institute  
**Student ID:** e174142@metu.edu.tr  

---

## ðŸ“– Project Overview  
This repository contains the PhaseÂ 1 deliverables for the DI725 final project, which aims to enhance the PaliGemma visionâ€“language model for remote sensing image captioning (RSIC) using the RISC dataset.  

**Key goals for PhaseÂ 1:**  
1. Conduct a concise literature survey of â‰¥Â 4 highâ€‘impact papers on RSIC and VLMs.  
2. Formulate a clear research question focusing on parameterâ€‘efficient fineâ€‘tuning (LoRA) and caption preprocessing.  
3. Perform exploratory data analysis (EDA) on RISC to identify dataset characteristics and inconsistencies.  
4. Initialize version control (this repo) and experiment tracking (W&B).  

---

## ðŸ“‚ Repository Structure  
/ â”œâ”€ data/ # (not committed) placeholder for RISC dataset
â”œâ”€ notebooks/ # Jupyter notebooks
â”‚ â””â”€ eda_risc.ipynb # EDA on caption lengths, vocab, image-caption pairs
â”œâ”€ reports/
â”‚ â””â”€ DI725_project_phase1_e174142_report.pdf # 2â€‘page IEEE PDF of PhaseÂ 1 deliverables
â”œâ”€ figures/
â”‚ â””â”€ caption_length_histogram.png
â”œâ”€ requirements.txt # Python dependencies
â””â”€ README.md # This file
